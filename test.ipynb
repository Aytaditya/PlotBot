{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain langchain-openai python-dotenv beautifulsoup4 google-search-results langchain_text_splitters langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "url=\"https://en.wikipedia.org/wiki/PK_(film)\"\n",
    "loader = WebBaseLoader(url)\n",
    "documents = loader.load()\n",
    "print(documents[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Title: Game of Thrones\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Extract the main movie or show name (title only, no extra words) from this question:\n",
    "\n",
    "Question: \"{question}\"\n",
    "\n",
    "Only return the movie/show name.\n",
    "\"\"\")\n",
    "\n",
    "def extract_title_via_llm(question: str) -> str:\n",
    "    chain = prompt | llm\n",
    "    result = chain.invoke({\"question\": question}).content.strip()\n",
    "    return chain.invoke({\"question\": question}).content.strip()\n",
    "\n",
    "extracted_title = extract_title_via_llm(\"what happens at the end of game of thrones\")\n",
    "print(\"Extracted Title:\", extracted_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "serp_api_key = os.getenv(\"SERP_API_KEY\")\n",
    "\n",
    "# Define search parameters\n",
    "params = {\n",
    "    \"num\": 5,\n",
    "    \"gl\": \"us\",\n",
    "    \"hl\": \"en\",\n",
    "    \"engine\": \"google\",\n",
    "    \"device\": \"desktop\",\n",
    "    \"google_domain\": \"google.com\"\n",
    "}\n",
    "\n",
    "# Initialize SerpAPI Wrapper\n",
    "search = SerpAPIWrapper(serpapi_api_key=serp_api_key, params=params)\n",
    "\n",
    "# Define the query\n",
    "extracted_title = \"Inception\"\n",
    "query = f\"{extracted_title} wikipedia\"\n",
    "\n",
    "# Perform the search and get structured results\n",
    "results = search.results(query)\n",
    "\n",
    "# Extract organic results\n",
    "organic_results = results.get(\"organic_results\", [])\n",
    "\n",
    "# Print results\n",
    "print(\"üîç Top Organic Search Results:\")\n",
    "if not organic_results:\n",
    "    print(\"No organic results found.\")\n",
    "else:\n",
    "    for i, result in enumerate(organic_results, 1):\n",
    "        title = result.get(\"title\", \"No Title\")\n",
    "        link = result.get(\"link\", \"No Link\")\n",
    "        snippet = result.get(\"snippet\", \"No Snippet\")\n",
    "        print(f\"\\nüîπ Result {i}\")\n",
    "        print(f\"üîó Title: {title}\")\n",
    "        print(f\"üåê URL: {link}\")\n",
    "        print(f\"üìù Snippet: {snippet}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ Extracted Title: Apple product roadmap\n",
      "üîó Wikipedia URL: https://en.wikipedia.org/wiki/List_of_Apple_products\n",
      "üìÑ Loaded 55658 characters from Wikipedia.\n",
      "\n",
      "üí¨ Answer:\n",
      "Based on the provided context, the next Apple product launch is scheduled for **July 15, 2024**, with the release of the **HomePod Mini (midnight)**.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "import chromadb\n",
    "from uuid import uuid4\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "serp_api_key = os.getenv(\"SERP_API_KEY\")\n",
    "\n",
    "# LLM and Embeddings\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    openai_api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    deployment_name=\"gpt-4.1\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=\"text-embedding-3-large\",\n",
    "    openai_api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    openai_api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    chunk_size=1000\n",
    ")\n",
    "\n",
    "# Search configuration\n",
    "params = {\n",
    "    \"num\": 5,\n",
    "    \"gl\": \"us\",\n",
    "    \"hl\": \"en\",\n",
    "    \"engine\": \"google\",\n",
    "    \"device\": \"desktop\",\n",
    "    \"google_domain\": \"google.com\"\n",
    "}\n",
    "search = SerpAPIWrapper(serpapi_api_key=serp_api_key, params=params)\n",
    "\n",
    "# Title extraction prompt\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an expert analyst assistant.\n",
    "\n",
    "Extract the core business query topic from the user's question. Your answer should be short and precise, combining the company/product name and the business intent.\n",
    "\n",
    "Examples:\n",
    "- Question: \"Is OpenAI profitable yet?\" ‚Üí Answer: \"OpenAI profitability\"\n",
    "- Question: \"What are the growth plans of SpaceX?\" ‚Üí Answer: \"SpaceX future plans\"\n",
    "- Question: \"How is Google's AI division performing?\" ‚Üí Answer: \"Google AI performance\"\n",
    "- Question: \"What is Apple's next product launch?\" ‚Üí Answer: \"Apple product roadmap\"\n",
    "\n",
    "Now, analyze and extract the main topic:\n",
    "\n",
    "Question: \"{question}\"\n",
    "\n",
    "Return only the business query topic.\n",
    "\"\"\")\n",
    "\n",
    "def extract_title_via_llm(question: str) -> str:\n",
    "    chain = prompt | llm\n",
    "    return chain.invoke({\"question\": question}).content.strip()\n",
    "\n",
    "def get_wikipedia_link(extracted_title: str) -> str:\n",
    "    query = f\"{extracted_title} site:techcrunch.com OR site:bloomberg.com OR site:businessinsider.com OR site:wikipedia.org\"\n",
    "    results = search.results(query)\n",
    "    organic_results = results.get(\"organic_results\", [])\n",
    "    return organic_results[0].get(\"link\", None) if organic_results else None\n",
    "\n",
    "def load_wikipedia_content(url: str) -> str:\n",
    "    loader = WebBaseLoader(url)\n",
    "    docs = loader.load()\n",
    "    return docs[0].page_content if docs else \"No content loaded.\"\n",
    "\n",
    "\n",
    "def create_vectorstore(content: str):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    split_texts = splitter.split_text(content)\n",
    "    documents = [Document(page_content=text, metadata={\"source\": \"Wikipedia\"}) for text in split_texts]\n",
    "    uuids = [str(uuid4()) for _ in documents]\n",
    "\n",
    "    client = chromadb.PersistentClient(path=\"./chroma_store\")\n",
    "    collection_name = \"wikipedia_rag\"\n",
    "\n",
    "    vectorstore = Chroma(\n",
    "        client=client,\n",
    "        collection_name=collection_name,\n",
    "        embedding_function=embeddings\n",
    "    )\n",
    "\n",
    "    vectorstore.add_documents(documents=documents, ids=uuids)\n",
    "    return vectorstore\n",
    "\n",
    "def run_rag_pipeline(user_question: str):\n",
    "    title = extract_title_via_llm(user_question)\n",
    "    print(\"üé¨ Extracted Title:\", title)\n",
    "\n",
    "    wiki_url = get_wikipedia_link(title)\n",
    "    print(\"üîó Wikipedia URL:\", wiki_url)\n",
    "\n",
    "    if not wiki_url:\n",
    "        print(\"‚ùå Could not find Wikipedia link.\")\n",
    "        return\n",
    "\n",
    "    vectorstore = create_vectorstore(content)\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "    # Prompt\n",
    "    qa_prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=\"\"\"Use the following context to answer the question as accurately as possible.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Answer:\"\"\"\n",
    "    )\n",
    "\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        chain_type=\"stuff\",\n",
    "        chain_type_kwargs={\"prompt\": qa_prompt},\n",
    "        return_source_documents=False\n",
    "    )\n",
    "\n",
    "    answer = qa_chain.run(user_question)\n",
    "\n",
    "    print(\"\\nüí¨ Answer:\")\n",
    "    print(answer)\n",
    "\n",
    "\n",
    "# üîß Run the pipeline\n",
    "run_rag_pipeline(\"What is Apple's next product launch?\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
